{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import length\n",
    "from pyspark.sql import udf\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "import re\n",
    "sql = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms = sql.read.format('com.databricks.spark.csv').option('delimiter', '\\t').load('spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+\n",
      "|class|                text|length|\n",
      "+-----+--------------------+------+\n",
      "|  ham|Go until jurong p...|   111|\n",
      "|  ham|Ok lar... Joking ...|    29|\n",
      "| spam|Free entry in 2 a...|   155|\n",
      "|  ham|U dun say so earl...|    49|\n",
      "|  ham|Nah I don't think...|    61|\n",
      "| spam|FreeMsg Hey there...|   147|\n",
      "|  ham|Even my brother i...|    77|\n",
      "|  ham|As per your reque...|   160|\n",
      "| spam|WINNER!! As a val...|   157|\n",
      "| spam|Had your mobile 1...|   154|\n",
      "|  ham|I'm gonna be home...|   109|\n",
      "| spam|SIX chances to wi...|   136|\n",
      "| spam|URGENT! You have ...|   155|\n",
      "|  ham|I've been searchi...|   196|\n",
      "|  ham|I HAVE A DATE ON ...|    35|\n",
      "| spam|XXXMobileMovieClu...|   149|\n",
      "|  ham|Oh k...i'm watchi...|    26|\n",
      "|  ham|Eh u remember how...|    81|\n",
      "|  ham|Fine if thats th...|    56|\n",
      "| spam|England v Macedon...|   155|\n",
      "+-----+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sms = sms.withColumnRenamed('_c0','class').withColumnRenamed('_c1','text')\n",
    "sms = sms.withColumn('length', length(sms['text']))\n",
    "sms.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|class|count(1)|\n",
      "+-----+--------+\n",
      "|  ham|    4827|\n",
      "| spam|     747|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sms.createOrReplaceTempView('sms')\n",
    "sql.sql('select class, count(*) from sms group by class').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.remove_punctuation>"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuation(text):\n",
    "    \n",
    "    text=text.lower().strip()\n",
    "    text=re.sub(\"[^a-zA-Z]\", \" \", text).split()\n",
    "    \n",
    "    return text\n",
    "\n",
    "spark.udf.register(\"remove_punctuation\", remove_punctuation, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+--------------------+\n",
      "|class|                text|length|          token_text|\n",
      "+-----+--------------------+------+--------------------+\n",
      "|  ham|Go until jurong p...|   111|[go, until, juron...|\n",
      "|  ham|Ok lar... Joking ...|    29|[ok, lar, joking,...|\n",
      "| spam|Free entry in 2 a...|   155|[free, entry, in,...|\n",
      "|  ham|U dun say so earl...|    49|[u, dun, say, so,...|\n",
      "|  ham|Nah I don't think...|    61|[nah, i, don, t, ...|\n",
      "| spam|FreeMsg Hey there...|   147|[freemsg, hey, th...|\n",
      "|  ham|Even my brother i...|    77|[even, my, brothe...|\n",
      "|  ham|As per your reque...|   160|[as, per, your, r...|\n",
      "| spam|WINNER!! As a val...|   157|[winner, as, a, v...|\n",
      "| spam|Had your mobile 1...|   154|[had, your, mobil...|\n",
      "|  ham|I'm gonna be home...|   109|[i, m, gonna, be,...|\n",
      "| spam|SIX chances to wi...|   136|[six, chances, to...|\n",
      "| spam|URGENT! You have ...|   155|[urgent, you, hav...|\n",
      "|  ham|I've been searchi...|   196|[i, ve, been, sea...|\n",
      "|  ham|I HAVE A DATE ON ...|    35|[i, have, a, date...|\n",
      "| spam|XXXMobileMovieClu...|   149|[xxxmobilemoviecl...|\n",
      "|  ham|Oh k...i'm watchi...|    26|[oh, k, i, m, wat...|\n",
      "|  ham|Eh u remember how...|    81|[eh, u, remember,...|\n",
      "|  ham|Fine if thats th...|    56|[fine, if, that, ...|\n",
      "| spam|England v Macedon...|   155|[england, v, mace...|\n",
      "+-----+--------------------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sms = sql.sql('select *, remove_punctuation(text) as token_text from sms')\n",
    "sms.createOrReplaceTempView('sms')\n",
    "sms.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ham, testing_ham = sql.sql('select * from sms where class=\"ham\"').randomSplit([0.8, 0.2], seed = 10)\n",
    "training_spam, testing_spam = sql.sql('select * from sms where class=\"spam\"').randomSplit([0.8, 0.2], seed = 10)\n",
    "training = training_ham.unionAll(training_spam)\n",
    "testing = training_spam.unionAll(testing_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover, Tokenizer, StringIndexer, VectorAssembler, IDF, CountVectorizer, Word2Vec\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, LinearSVC, NaiveBayes\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopremove = StopWordsRemover(inputCol='token_text', outputCol='stop_tokens')\n",
    "count_vec = CountVectorizer(inputCol='stop_tokens', outputCol='c_vec')\n",
    "idf = IDF(inputCol=\"c_vec\", outputCol=\"tf_idf\")\n",
    "ham_spam_to_num = StringIndexer(inputCol='class', outputCol='label')\n",
    "clean_up = VectorAssembler(inputCols=['tf_idf','length'], outputCol='features')\n",
    "\n",
    "\n",
    "lr = LogisticRegression()\n",
    "svm = LinearSVC()\n",
    "dtc = DecisionTreeClassifier()\n",
    "nb = NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipeline(preprocessing_pipeline, model):\n",
    "    \n",
    "    return Pipeline(stages = preprocessing_pipeline + [model])\n",
    "\n",
    "\n",
    "def evaluate(training, testing, preprocessing_pipeline, model):\n",
    "    \n",
    "    model = get_pipeline(preprocessing_pipeline, model).fit(training)\n",
    "    prediction = model.transform(testing)\n",
    "    acc = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='accuracy').evaluate(prediction)\n",
    "    f1 = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='f1').evaluate(prediction)\n",
    "    print(f'Accuracy : {acc} F1-score : {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_pipeline = [stopremove, count_vec, idf, ham_spam_to_num, clean_up]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9585006693440429 F1-score : 0.9788106630211896\n"
     ]
    }
   ],
   "source": [
    "evaluate(training, testing, preprocessing_pipeline, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.7188755020080321 F1-score : 0.836448598130841\n"
     ]
    }
   ],
   "source": [
    "evaluate(training, testing, preprocessing_pipeline, dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9571619812583668 F1-score : 0.9781121751025993\n"
     ]
    }
   ],
   "source": [
    "evaluate(training, testing, preprocessing_pipeline, svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9852744310575636 F1-score : 0.9925826028320972\n"
     ]
    }
   ],
   "source": [
    "evaluate(training, testing, preprocessing_pipeline, nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|     word|              vector|\n",
      "+---------+--------------------+\n",
      "|     buns|[0.00452330429106...|\n",
      "|  serious|[5.42592722922563...|\n",
      "|    lover|[0.01670911349356...|\n",
      "|     rate|[0.01607220619916...|\n",
      "|     snow|[0.00892466586083...|\n",
      "|    looks|[-0.0069542448036...|\n",
      "|locations|[0.01299875974655...|\n",
      "|    sweet|[0.00539758428931...|\n",
      "|     used|[0.00302504608407...|\n",
      "|reference|[0.00619605137035...|\n",
      "|        e|[0.05535818263888...|\n",
      "| custcare|[0.01292549166828...|\n",
      "|     hiya|[0.00621117092669...|\n",
      "|beautiful|[0.01255329698324...|\n",
      "|     poly|[0.02419165149331...|\n",
      "|      ntt|[-0.0131739843636...|\n",
      "|   sunday|[-0.0098504303023...|\n",
      "|    funny|[0.01139319501817...|\n",
      "| birthday|[0.02177138067781...|\n",
      "|      lik|[0.00580250844359...|\n",
      "+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word2vec = Word2Vec(vectorSize = 300, seed = 10, inputCol = 'token_text', outputCol = 'model')\n",
    "model = word2vec.fit(sms)\n",
    "model.getVectors().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_assembler = VectorAssembler(inputCols=['model'], outputCol='features')\n",
    "ham_spam_to_num = StringIndexer(inputCol='class', outputCol='label')\n",
    "new_pipeline = [model, vector_assembler, ham_spam_to_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8835341365461847 F1-score : 0.9381663113006398\n"
     ]
    }
   ],
   "source": [
    "evaluate(training, testing, new_pipeline, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8714859437751004 F1-score : 0.9313304721030042\n"
     ]
    }
   ],
   "source": [
    "evaluate(training, testing, new_pipeline, dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8406961178045516 F1-score : 0.9134545454545454\n"
     ]
    }
   ],
   "source": [
    "evaluate(training, testing, new_pipeline, svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Не вистачає екзамплів для word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopremove = StopWordsRemover(inputCol='token_text', outputCol='stop_tokens')\n",
    "count_vec = CountVectorizer(inputCol='stop_tokens', outputCol='c_vec')\n",
    "idf = IDF(inputCol=\"c_vec\", outputCol=\"tf_idf\")\n",
    "ham_spam_to_num = StringIndexer(inputCol='class', outputCol='label')\n",
    "clean_up = VectorAssembler(inputCols=['tf_idf','length', 'model'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_pipeline = [stopremove, count_vec, idf, ham_spam_to_num, model, clean_up]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9718875502008032 F1-score : 0.985743380855397\n"
     ]
    }
   ],
   "source": [
    "evaluate(training, testing, preprocessing_pipeline, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9183400267737617 F1-score : 0.9574319609211445\n"
     ]
    }
   ],
   "source": [
    "evaluate(training, testing, preprocessing_pipeline, dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9772423025435074 F1-score : 0.988490182802979\n"
     ]
    }
   ],
   "source": [
    "evaluate(training, testing, preprocessing_pipeline, svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Linear SVC - the best."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
